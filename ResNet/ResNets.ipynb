{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch实现ResNet全系列\n",
    "用PyTorch实现ResNet，包括ResNet18，ResNet34，ResNet50等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__all__=['ResNet','resnet18','resnet34','resnet50','resnet101','resnet152']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#添加预训练权重的URL\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将卷积层进行一次封装\n",
    "def conv3x3(in_planes,out_planes,stride=1):\n",
    "    return nn.Conv2d(in_planes,out_planes,kernel_size=3,stride=stride,padding=1,bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Block单元\n",
    "这里就是这个系列的区别，像resnet18和34这类比较轻小的网络使用的是basic block单元。像50和101这类使用的是BottleBlock这类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BasicBlock\n",
    "基础版的残差模块由两个叠加的3*3卷积组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion=1\n",
    "    \n",
    "    def __init__(self,inplanes,planes,stride=1,downsample=None):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1=conv3x3(inplanes,planes,stride)\n",
    "        self.bn1=nn.BatchNorm2d(planes)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.conv2=conv3x3(planes,planes)\n",
    "        self.bn2=nn.BatchNorm2d(planes)\n",
    "        self.downsample=downsample\n",
    "        self.stride=stride\n",
    "    def forward(self,x):\n",
    "        residual=x#残差单元，就是开始的输入\n",
    "        \n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.relu(out)\n",
    "        \n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual=self.downsample(x)\n",
    "        \n",
    "        out+=residual#就这样实现了残差连接，就这么简单\n",
    "        out=self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottleneck\n",
    "这个模块主要是ResNet50和ResNet101使用的，与基础版本不同的是这里有三个卷积，分别是1x1,3x3,1x1分别用来压缩维度，卷积处理，恢复维度，inplane是输入的通道，plane是输出的通道，expansion是对输出通道数的倍乘，在基础版的这个参数为1则可以忽略不计。输出的就是plane。而在bottleneck它的任务就是对通道数进行压缩，再放大，plane不再代表输出的通道数，而是block内部压缩后的通道数，输出通道变为plane*expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion=4\n",
    "    \n",
    "    def __init__(self,inplanes,planes,stride=1,downsample=None):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.conv1=nn.Conv2d(inplanes,planes,kernel_size=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(planes)\n",
    "        self.conv2=nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(planes)\n",
    "        self.conv3=nn.Conv2d(planes,planes*self.expansion,kernel_size=1,bias=False)\n",
    "        self.bn3=nn.BatchNorm2d(planes*self.expansion)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.downsample=downsample\n",
    "        self.stride=stride\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual=x\n",
    "        \n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.relu(out)\n",
    "        \n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.relu(out)\n",
    "        \n",
    "        out=self.conv3(out)\n",
    "        out=self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual=self.downsample(x)\n",
    "        out+=residual\n",
    "        out=self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义ResNet网络主体\n",
    "resnet共有5个阶段，其中第一阶段为7x7的卷积处理，stride为2，然后经过池化处理，此时特征图的尺寸为输入的1/4,接下来四个阶段用make_layer函数产生四个layer，需要用户输入每个layer的block数目以及采用的block类型(基础版还是bottleneck版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,block,layers,num_classes=1000):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.inplaces=64\n",
    "        self.conv1=nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.layer1=self._make_layer(block,64,layers[0])\n",
    "        self.layer2=self._make_layer(block,128,layers[1],stride=2)\n",
    "        self.layer3=self._make_layer(block,256,layers[2],stride=2)\n",
    "        self.layer4=self._make_layer(block,512,layers[3],stride=2)\n",
    "        self.avgpool=nn.AvgPool2d(7,stride=1)\n",
    "        self.fc=nn.Linear(512*block.expansion,num_classes)\n",
    "        #卷积核以及BN的权值初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')#权重初始化\n",
    "            elif isinstance(m,nn.BatchNorm2d):#BatchNorm2d批规范的初始化\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self,block,planes,blocks,stride=1):\n",
    "        downsample=None\n",
    "        if stride!=1 or self.inplaces!=planes*block.expansion:\n",
    "            downsample=nn.Sequential(\n",
    "                nn.Conv2d(self.inplaces,planes*block.expansion,\n",
    "                         kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(planes*block.expansion),\n",
    "            )\n",
    "        layers=[]\n",
    "        layers.append(block(self.inplaces,planes,stride,downsample))\n",
    "        self.inplaces=planes*block.expansion#这里更改inplaces值\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(self.inplaces,planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet50(pretrained=False,**kwargs):\n",
    "    model=ResNet(Bottleneck,[3,4,6,3],**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义各个模型\n",
    "包括resnet18,resnet34,resnet50,resnet102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resnet18模型\n",
    "def resnet18(pretrained=False,**kwargs):\n",
    "    model=ResNet(BasicBlock,[2,2,2,2],**kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "#resnet34模型\n",
    "def resnet34(pretrained=False,**kwargs):\n",
    "    model=ResNet(BasicBlock,[3,4,6,3],**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "#resnet50模型\n",
    "def resnet50(pretrained=False,**kwargs):\n",
    "    model=ResNet(Bottleneck,[3,4,6,3],**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "#resnet101模型\n",
    "def resnet101(pretrained=False,**kwargs):\n",
    "    model=ResNet(Bottleneck,[3,4,23,3],**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "#resnet152模型\n",
    "def resnet152(pretrained=False,**kwargs):\n",
    "    model=ResNet(Bottleneck,[3,8,36,3],**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet18=resnet18()\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thop\n",
      "  Downloading thop-0.0.31.post2005141830-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: torch in /Users/gongpengwang/anaconda/anaconda3/envs/pytorch_py3.6/lib/python3.6/site-packages (from thop) (1.4.0)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.0.31.post2005141830\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Users/gongpengwang/anaconda/anaconda3/envs/pytorch_py3.6/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net=resnet50()\n",
    "inp=torch.rand(1,3,224,224)\n",
    "out=net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
